{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('the-verdict.txt', <http.client.HTTPMessage at 0x204dc7a2030>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = (\"https://raw.githubusercontent.com/rasbt/\"\n",
    " \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n",
    " \"the-verdict.txt\")\n",
    "file_path = \"the-verdict.txt\"\n",
    "urllib.request.urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of character: 20479\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
     ]
    }
   ],
   "source": [
    "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    " raw_text = f.read()\n",
    "print(\"Total number of character:\", len(raw_text))\n",
    "print(raw_text[:99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text-to-token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
     ]
    }
   ],
   "source": [
    "text = 'Hello, world. Is this-- a test?'\n",
    "# match either a comma, a period..., OR any --, OR any whitespace\n",
    "result = re.split(r'([,.?!:;_\"()\\']|--|\\s)', text)\n",
    "# bool(' '.strip()) -> False \n",
    "result = [item.strip() for item in result if item.strip()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4690\n"
     ]
    }
   ],
   "source": [
    "preprocessed = re.split(r'([,.?!:;_\"()\\']|--|\\s)', raw_text)\n",
    "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "print(len(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'HAD', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to', 'hear', 'that', ',', 'in']\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Token-to-tokenID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1132\n"
     ]
    }
   ],
   "source": [
    "# list of unique words = vocabulary\n",
    "all_tokens = sorted(set(preprocessed))\n",
    "all_tokens.extend([\"<|endoftext|>\", \"<|unk|>\"])  # unkown tokens, unrelated tokens\n",
    "vocab = {token: integer for integer, token in enumerate(all_tokens)}  # vocabulary dictionary type {token: id}\n",
    "\n",
    "print(len(vocab.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('younger', 1127)\n",
      "('your', 1128)\n",
      "('yourself', 1129)\n",
      "('<|endoftext|>', 1130)\n",
      "('<|unk|>', 1131)\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(list(vocab.items())[-5:]):\n",
    "    print(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder and Decoder = Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV1:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab \n",
    "        self.int_to_str = {i:s for s,i in vocab.items()} \n",
    " \n",
    "    def encode(self, text): \n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    " \n",
    "    def decode(self, ids): \n",
    "        text = \" \".join([self.int_to_str[i] for i in ids]) \n",
    " \n",
    "        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text) \n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 56, 2, 850, 988, 602, 533, 746, 5, 1126, 596, 5, 1, 67, 7, 38, 851, 1108, 754, 793, 7]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV1(vocab)\n",
    "text = \"\"\"\"It's the last he painted, you know,\" \n",
    " Mrs. Gisburn said with pardonable pride.\"\"\"\n",
    "ids = tokenizer.encode(text)\n",
    "print(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTokenizerV2:\n",
    "    def __init__(self, vocab):\n",
    "        self.str_to_int = vocab \n",
    "        self.int_to_str = {i:s for s,i in vocab.items()} \n",
    " \n",
    "    def encode(self, text): \n",
    "        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n",
    "        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
    "        preprocessed = [item if item in self.str_to_int else \"<|unk|>\" for item in preprocessed]\n",
    "        ids = [self.str_to_int[s] for s in preprocessed]\n",
    "        return ids\n",
    " \n",
    "    def decode(self, ids): \n",
    "        text = \" \".join([self.int_to_str[i] for i in ids]) \n",
    " \n",
    "        text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text) \n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, do you like tea? <|endoftext|> In the sunlit terraces of the palace.\n"
     ]
    }
   ],
   "source": [
    "text1 = \"Hello, do you like tea?\"\n",
    "text2 = \"In the sunlit terraces of the palace.\"\n",
    "text = \" <|endoftext|> \".join((text1, text2))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1131, 5, 355, 1126, 628, 975, 10, 1130, 55, 988, 956, 984, 722, 988, 1131, 7]\n",
      "<|unk|>, do you like tea? <|endoftext|> In the sunlit terraces of the <|unk|>.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = SimpleTokenizerV2(vocab)\n",
    "print(tokenizer.encode(text))\n",
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Byte pair encoding (BPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken version: 0.9.0\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "import tiktoken\n",
    "print(\"tiktoken version:\", version(\"tiktoken\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 11, 466, 345, 588, 8887, 30, 220, 50256, 554, 262, 4252, 18250, 8812, 2114, 1659, 617, 34680, 27271, 13]\n",
      "Hello, do you like tea? <|endoftext|> In the sunlit terracesof someunknownPlace.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "text = (\n",
    " \"Hello, do you like tea? <|endoftext|> In the sunlit terraces\"\n",
    " \"of someunknownPlace.\")\n",
    "integers = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "print(integers)\n",
    "\n",
    "strings = tokenizer.decode(integers)\n",
    "print(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33901, 86, 343, 86, 220, 959]\n",
      "Akwirw ier\n"
     ]
    }
   ],
   "source": [
    "# Ex 2.1 unkown word\n",
    "unknown_word = \"Akwirw ier\"\n",
    "unknown_integers = tokenizer.encode(unknown_word)\n",
    "print(unknown_integers)\n",
    "\n",
    "unknown_strings = tokenizer.decode(unknown_integers)\n",
    "print(unknown_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145\n"
     ]
    }
   ],
   "source": [
    "enc_text = tokenizer.encode(raw_text)\n",
    "print(len(enc_text))\n",
    "\n",
    "enc_sample = enc_text[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset for batched inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text to \n",
    "class GPTDatasetV1(Dataset):\n",
    "    def __init__(self, txt, tokenizer, max_length, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "\n",
    "        token_ids = tokenizer.encode(txt)\n",
    "\n",
    "        for i in range(0, len(token_ids) - max_length, stride):\n",
    "            input_chunk = token_ids[i : i + max_length]\n",
    "            target_chunk = token_ids[i + 1 : i + 1 + max_length]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    # single row with 2 tensors: input_chunk, target_chunk\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "    \n",
    "# dataloader\n",
    "def create_dataloader_v1(txt, batch_size=4, max_length=256, stride=128, shuffle=True, drop_last=True, num_workers=0):\n",
    "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)   \n",
    "\n",
    "    return dataloader                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[  40,  367, 2885, 1464, 1807, 3619,  402,  271]]), tensor([[  367,  2885,  1464,  1807,  3619,   402,   271, 10899]])]\n",
      "[tensor([[ 2885,  1464,  1807,  3619,   402,   271, 10899,  2138]]), tensor([[ 1464,  1807,  3619,   402,   271, 10899,  2138,   257]])]\n"
     ]
    }
   ],
   "source": [
    "with open (\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# batch_size = how many samples to process in parallel each iteration\n",
    "# stride = number of positions to shift inputs each batches\n",
    "# max_length = sliding window size (number of columns)\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=1, max_length=8, stride=2, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "first_batch = next(data_iter) \n",
    "print(first_batch) \n",
    "\n",
    "second_batch = next(data_iter)\n",
    "print(second_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]]) \n",
      "tsargets: tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   922],\n",
      "        [ 5891,  1576,   438,   568],\n",
      "        [  340,   373,   645,  1049],\n",
      "        [ 5975,   284,   502,   284],\n",
      "        [ 3285,   326,    11,   287]])\n"
     ]
    }
   ],
   "source": [
    "# test batch sizes > 1\n",
    "dataloader = create_dataloader_v1(raw_text, batch_size=8, max_length=4, stride=4, shuffle=False)\n",
    "data_iter = iter(dataloader)\n",
    "inputs, targets = next(data_iter)\n",
    "print(\"inputs:\", inputs, \"\\ntsargets:\", targets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n",
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-2.8400, -0.7849, -1.4096],\n",
      "        [ 0.9178,  1.5810,  1.3010]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input_ids = torch.tensor([2, 3, 5, 1])\n",
    "\n",
    "vocab_size = 6\n",
    "output_dim = 3\n",
    "\n",
    "torch.manual_seed(123)\n",
    "# Embedding layer with (vocab_size x output_dim) weight matrix, mapping input indices to dense vectors\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_dim)  \n",
    "print(embedding_layer.weight)  # weight matrix\n",
    "\n",
    "# apply to input_ids to get embedding vector\n",
    "#                                   2idx↓, 3idx↓, 5idx↓, 1idx↓\n",
    "print(embedding_layer(torch.tensor([2,     3,     5,     1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Positional Token embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Example tensor\n",
    "tensor = torch.randn(8, 4, 256)\n",
    "\n",
    "# Visualize the first sample as a heatmap\n",
    "sample = tensor[0].numpy()\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.heatmap(sample, cmap='viridis')\n",
    "plt.xlabel('Features (256)')\n",
    "plt.ylabel('Channels (4)')\n",
    "plt.title('Heatmap of [4, 256] slice from [8, 4, 256] Tensor')\n",
    "plt.show()\n",
    "\n",
    "# ↓ 8 of this stacked together\n",
    "# 8 = number of stacks\n",
    "# 4 = each token \n",
    "# 256 = each token represented as 256 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50257, 256])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 50257\n",
    "output_dim = 256\n",
    "token_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n",
    "print(token_embedding_layer.weight.shape) # weight matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token ids:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  922,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "inputs shape:\n",
      " torch.Size([8, 4])\n"
     ]
    }
   ],
   "source": [
    "# 8 sample with 4 token each\n",
    "max_length = 4\n",
    "dataloader = create_dataloader_v1(\n",
    "    raw_text, batch_size=8, max_length=max_length, stride=max_length, shuffle=False\n",
    ")\n",
    "data_ite = iter(dataloader)\n",
    "iniputs, targets = next(data_iter)\n",
    "print(f\"token ids:\\n {inputs}\")\n",
    "print(f\"inputs shape:\\n {iniputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = token_embedding_layer(inputs)  # (8, 4)\n",
    "print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "contex_length = max_length\n",
    "pos_embedding_layer = torch.nn.Embedding(contex_length, output_dim)\n",
    "pos_embeddings = pos_embedding_layer(torch.arange(contex_length))  # placeholder vector\n",
    "print(pos_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# add pos_embeddings to token_embeddings = input_embeddings (read to be processes by LLM)\n",
    "input_embeddings = token_embeddings + pos_embeddings\n",
    "print(input_embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self attention (ch.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "inputs = torch.tensor(\n",
    " [[0.43, 0.15, 0.89], # Your (x^1)\n",
    " [0.55, 0.87, 0.66], # journey (x^2)\n",
    " [0.57, 0.85, 0.64], # starts (x^3)\n",
    " [0.22, 0.58, 0.33], # with (x^4)\n",
    " [0.77, 0.25, 0.10], # one (x^5)\n",
    " [0.05, 0.80, 0.55]] # step (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5500, 0.8700, 0.6600])\n",
      "tensor([0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865])\n"
     ]
    }
   ],
   "source": [
    "# calculate attention score ω(dot product of query token and all other input tokens)\n",
    "query = inputs[1]\n",
    "attn_scores_2 = torch.empty(inputs.shape[0])  # uninitialized tensor\n",
    "for i, x_i in enumerate(inputs):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query)  # dot product\n",
    "\n",
    "print(query)\n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights: tensor([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581])\n",
      "Sum: tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "# attention weights α(normalize attention scores using softmax function)\n",
    "# ~ torch.exp(x) / torch.exp(x).sum(dim=0) → e^x / sum(e^x_i)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "\n",
    "print(\"Attention weights:\", attn_weights_2)\n",
    "print(\"Sum:\", attn_weights_2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([0.4419, 0.6515, 0.5683])\n"
     ]
    }
   ],
   "source": [
    "# context vector z(2)\n",
    "query = inputs[1]\n",
    "context_vec_2 = torch.zeros(query.shape)  # tensor([0., 0., 0.])\n",
    "for i, x_i in enumerate(inputs):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i  # α_0 * x_0 + ... + α_T * x_T\n",
    "\n",
    "print(query.shape)\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention scores:\n",
      " tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
      "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
      "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
      "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
      "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
      "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]]) \n",
      "\n",
      "Attention weights:\n",
      " tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
      "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
      "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
      "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
      "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
      "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])\n",
      "All row sums:\n",
      " tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000]) \n",
      "\n",
      "Context vectors:\n",
      " tensor([[0.4421, 0.5931, 0.5790],\n",
      "        [0.4419, 0.6515, 0.5683],\n",
      "        [0.4431, 0.6496, 0.5671],\n",
      "        [0.4304, 0.6298, 0.5510],\n",
      "        [0.4671, 0.5910, 0.5266],\n",
      "        [0.4177, 0.6503, 0.5645]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# all attention scores\n",
    "attn_scores = torch.empty(inputs.shape[0], inputs.shape[0])  # (6, 6)\n",
    "attn_scores = inputs @ inputs.T\n",
    "# 2nd solution (slow)\n",
    "# for i, x_i in enumerate(inputs):\n",
    "#     for j, x_j in enumerate(inputs):\n",
    "#         attn_scores[i, j] = torch.dot(x_i, x_j)\n",
    "print(\"Attention scores:\\n\", attn_scores, \"\\n\")\n",
    "\n",
    "# all attention weights (normalize attention scores)\n",
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "print(\"Attention weights:\\n\", attn_weights)\n",
    "print(\"All row sums:\\n\", attn_weights.sum(dim=-1), \"\\n\")\n",
    "\n",
    "# all context vectors (matrix multiplication)\n",
    "all_context_vec = attn_weights @ inputs\n",
    "print(\"Context vectors:\\n\", all_context_vec, \"\\n\")\n",
    "\n",
    "# print(\"inputs:\\n\", inputs)\n",
    "# print(\"inputs T:\\n\", inputs.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self attention with trainable weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4306, 1.4551])\n"
     ]
    }
   ],
   "source": [
    "x_2 = inputs[1] \n",
    "d_in = inputs.shape[1]  # 3\n",
    "d_out = 2 \n",
    "\n",
    "# weight matrices W_q, W_k, and W_v\n",
    "torch.manual_seed(123)\n",
    "W_query = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_key = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "W_value = torch.nn.Parameter(torch.rand(d_in, d_out), requires_grad=False)\n",
    "\n",
    "# compute query, key and value  vectors\n",
    "query_2 = x_2 @ W_query\n",
    "key_2 = inputs @ W_key\n",
    "value_2 = inputs @ W_value\n",
    "print(query_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys.shape: torch.Size([6, 2])\n",
      "values.shape: torch.Size([6, 2])\n"
     ]
    }
   ],
   "source": [
    "# all keys and values\n",
    "keys = inputs @ W_key \n",
    "values = inputs @ W_value\n",
    "print(\"keys.shape:\", keys.shape)\n",
    "print(\"values.shape:\", values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.2705, 1.8524, 1.8111, 1.0795, 0.5577, 1.5440])\n"
     ]
    }
   ],
   "source": [
    "# attention scores for 2nd query\n",
    "attn_scores_2 = query_2 @ keys.T \n",
    "print(attn_scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1500, 0.2264, 0.2199, 0.1311, 0.0906, 0.1820])\n"
     ]
    }
   ],
   "source": [
    "# normalize attention scores → attention weights (propability destributions)\n",
    "d_k = keys.shape[-1]  # key dimension\n",
    "attn_weights_2 = torch.softmax(attn_scores_2 / torch.sqrt(torch.tensor(d_k)), dim=-1)  # or (.. / d_k**0.5, dim=-1)\n",
    "print(attn_weights_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3061, 0.8210])\n"
     ]
    }
   ],
   "source": [
    "# single context vector for 2nd query\n",
    "context_vec_2 = attn_weights_2 @ values\n",
    "print(context_vec_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orginize code in Python class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-attention class creation\n",
    "import torch.nn as nn\n",
    "class SelfAttentionScore_V1(nn.Module):\n",
    "    def __init__(self, d_in, d_out):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Parameter(torch.rand(d_in, d_out))  # this will be updated with nn.Linear\n",
    "        self.W_key = nn.Parameter(torch.rand(d_in, d_out))\n",
    "        self.W_value = nn.Parameter(torch.rand(d_in, d_out))\n",
    "\n",
    "    def forward(self, x):  # x is input vector\n",
    "        keys = x @ self.W_key\n",
    "        queries = x @ self.W_query\n",
    "        values = x @ self.W_value \n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(attn_scores / torch.sqrt(torch.tensor(keys.shape[-1])), dim=-1)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2996, 0.8053],\n",
      "        [0.3061, 0.8210],\n",
      "        [0.3058, 0.8203],\n",
      "        [0.2948, 0.7939],\n",
      "        [0.2927, 0.7891],\n",
      "        [0.2990, 0.8040]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# use self-attention class\n",
    "torch.manual_seed(123)\n",
    "sa_v1 = SelfAttentionScore_V1(d_in, d_out)  # object (3, 2)\n",
    "print(sa_v1(inputs))  # (6,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Linear uses a more sophisticated weight initialization scheme\n",
    "class SelfAttention_v2(nn.Module):\n",
    "    def __init__(self, d_in, d_out, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.T\n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# using SelfAttention_v2\n",
    "torch.manual_seed(789)\n",
    "sa_v2 = SelfAttention_v2(d_in, d_out)\n",
    "print(sa_v2(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.1 Comparing SelfAttention_v1 and SelfAttention_v2  \n",
    "   \n",
    "> Note that nn.Linear in SelfAttention_v2 uses a different weight initialization  \n",
    "> scheme as nn.Parameter(torch.rand(d_in, d_out)) used in SelfAttention_v1,  \n",
    "> which causes both mechanisms to produce different results. To check that both  \n",
    "> implementations, SelfAttention_v1 and SelfAttention_v2, are otherwise similar,  \n",
    "> we can transfer the weight matrices from a SelfAttention_v2 object to a SelfAttention_v1,  \n",
    "> such that both objects then produce the same results.  \n",
    "> Your task is to correctly assign the weights from an instance of SelfAttention_v2  \n",
    "> to an instance of SelfAttention_v1. To do this, you need to understand the relationship  \n",
    "> between the weights in both versions. (Hint: nn.Linear stores the weight  \n",
    "> matrix in a transposed form.) After the assignment, you should observe that both  \n",
    "> instances produce the same outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 output:\n",
      " tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n",
      "v2 output:\n",
      " tensor([[-0.0739,  0.0713],\n",
      "        [-0.0748,  0.0703],\n",
      "        [-0.0749,  0.0702],\n",
      "        [-0.0760,  0.0685],\n",
      "        [-0.0763,  0.0679],\n",
      "        [-0.0754,  0.0693]], grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# ex 3.1\n",
    "sa_v1.W_query.data = sa_v2.W_query.weight.data.T\n",
    "sa_v1.W_key.data = sa_v2.W_key.weight.data.T\n",
    "sa_v1.W_value.data = sa_v2.W_value.weight.data.T\n",
    "\n",
    "output_v1 = sa_v1(inputs)\n",
    "output_v2 = sa_v2(inputs)\n",
    "\n",
    "print(\"v1 output:\\n\", output_v1)\n",
    "print(\"v2 output:\\n\", output_v2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Casual Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1921, 0.1646, 0.1652, 0.1550, 0.1721, 0.1510],\n",
      "        [0.2041, 0.1659, 0.1662, 0.1496, 0.1665, 0.1477],\n",
      "        [0.2036, 0.1659, 0.1662, 0.1498, 0.1664, 0.1480],\n",
      "        [0.1869, 0.1667, 0.1668, 0.1571, 0.1661, 0.1564],\n",
      "        [0.1830, 0.1669, 0.1670, 0.1588, 0.1658, 0.1585],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "queries = sa_v2.W_query(inputs) \n",
    "keys = sa_v2.W_key(inputs) \n",
    "attn_scores = queries @ keys.T\n",
    "attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "print(attn_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1.]])\n",
      "normalized mask:  tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "tensor([[0.2899,   -inf,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4656, 0.1723,   -inf,   -inf,   -inf,   -inf],\n",
      "        [0.4594, 0.1703, 0.1731,   -inf,   -inf,   -inf],\n",
      "        [0.2642, 0.1024, 0.1036, 0.0186,   -inf,   -inf],\n",
      "        [0.2183, 0.0874, 0.0882, 0.0177, 0.0786,   -inf],\n",
      "        [0.3408, 0.1270, 0.1290, 0.0198, 0.1290, 0.0078]],\n",
      "       grad_fn=<MaskedFillBackward0>) torch.Size([6, 6])\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4483, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3800, 0.3097, 0.3103, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2460, 0.2462, 0.2319, 0.0000, 0.0000],\n",
      "        [0.2175, 0.1983, 0.1984, 0.1888, 0.1971, 0.0000],\n",
      "        [0.1935, 0.1663, 0.1666, 0.1542, 0.1666, 0.1529]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# efficient way\n",
    "# apply mask\n",
    "context_length = attn_scores.shape[0]\n",
    "mask_simple = torch.tril(torch.ones(context_length, context_length))  # lower triangle\n",
    "print(mask_simple)\n",
    "\n",
    "masked_simple = attn_weights*mask_simple\n",
    "# print(masked_simple)\n",
    "\n",
    "\n",
    "# renormalize: sum of each row = 1\n",
    "row_sums = masked_simple.sum(dim=-1, keepdim=True)  # [6,6] → [6,1]\n",
    "masked_simple_norm = masked_simple / row_sums\n",
    "print(\"normalized mask: \", masked_simple_norm)\n",
    "\n",
    "# -inf above diagonal\n",
    "mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)  # upper triangle of ones\n",
    "masked = attn_scores.masked_fill(mask.bool(), -torch.inf)  # 1=True → -inf\n",
    "print(masked, masked.shape)\n",
    "\n",
    "# atten_weights = softmax of masked \n",
    "attn_weights = torch.softmax(masked / keys.shape[-1]**0.5, dim=1)\n",
    "print(attn_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropout - prevent overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.],\n",
      "        [0., 0., 2., 0., 2., 0.],\n",
      "        [2., 2., 0., 0., 0., 2.],\n",
      "        [2., 0., 0., 0., 0., 2.],\n",
      "        [0., 2., 0., 0., 0., 0.]])\n",
      "tensor([[2.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.8966, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.6206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5517, 0.4921, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4350, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3327, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)  # generate same random numbers\n",
    "dropout = torch.nn.Dropout(0.5)  # Dropout layer, 50% of values will be set to 0, remaining scaled up by 1 / (1 - 0.5) = 2\n",
    "example = torch.ones(6, 6) \n",
    "print(dropout(example))\n",
    "\n",
    "# apply dropout to attention weights\n",
    "torch.manual_seed(123)\n",
    "print(dropout(attn_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Casual attention class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalAttention(nn.Module):\n",
    "    \"\"\"create query, key, value projection matrices from input\n",
    "        softmax(Q*K + mask)*V\n",
    "        casual mask blocks future tokens\n",
    "        return weighted output\n",
    "    \"\"\"\n",
    "    def __init__(self, d_in, d_out, context_length,\n",
    "    dropout, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        self.d_out = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)  # shape: (batch_size, context_length, d_out)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.dropout = nn.Dropout(dropout) \n",
    "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))  # mask moves with model to GPU\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape \n",
    "        keys = self.W_key(x)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "        attn_scores = queries @ keys.transpose(1, 2) \n",
    "        attn_scores.masked_fill_( \n",
    "        self.mask.bool()[:num_tokens, :num_tokens], -torch.inf) \n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1\n",
    "        )\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = attn_weights @ values\n",
    "        return context_vec     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# use casual attention class\n",
    "batch = torch.stack((inputs, inputs), dim=0)\n",
    "print(batch.shape) \n",
    "\n",
    "torch.manual_seed(123)\n",
    "context_length = batch.shape[1]\n",
    "ca = CausalAttention(d_in, d_out, context_length, 0.0)\n",
    "context_vecs = ca(batch)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multihead attention class with weight splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, \n",
    "    context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "        \"d_out must be divisible by num_heads\"\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads  # num_heads * head_dim = d_out\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out) \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "        \"mask\",\n",
    "        torch.triu(torch.ones(context_length, context_length),\n",
    "        diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "        keys = self.W_key(x) \n",
    "        queries = self.W_query(x) \n",
    "        values = self.W_value(x) \n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        queries = queries.view( \n",
    "        b, num_tokens, self.num_heads, self.head_dim \n",
    "        ) \n",
    "        keys = keys.transpose(1, 2) \n",
    "        queries = queries.transpose(1, 2) \n",
    "        values = values.transpose(1, 2) \n",
    "        attn_scores = queries @ keys.transpose(2, 3) \n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens] \n",
    "        \n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf) \n",
    "        attn_weights = torch.softmax(\n",
    "        attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        context_vec = context_vec.contiguous().view(\n",
    "        b, num_tokens, self.d_out\n",
    "        )\n",
    "        context_vec = self.out_proj(context_vec) \n",
    "        return context_vec\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]],\n",
      "\n",
      "        [[0.3190, 0.4858],\n",
      "         [0.2943, 0.3897],\n",
      "         [0.2856, 0.3593],\n",
      "         [0.2693, 0.3873],\n",
      "         [0.2639, 0.3928],\n",
      "         [0.2575, 0.4028]]], grad_fn=<ViewBackward0>)\n",
      "context_vecs.shape: torch.Size([2, 6, 2])\n"
     ]
    }
   ],
   "source": [
    "# use multihead attention \n",
    "torch.manual_seed(123)\n",
    "batch_size, context_length, d_in = batch.shape\n",
    "d_out = 2\n",
    "mha = MultiHeadAttention(d_in, d_out, context_length, 0.0, num_heads=2)\n",
    "context_vecs = mha(batch)\n",
    "print(context_vecs)\n",
    "print(\"context_vecs.shape:\", context_vecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3.3 Initializing GPT-2 size attention modules\n",
    "> Using the MultiHeadAttention class, initialize a multi-head attention module that\n",
    ">  has the same number of attention heads as the smallest GPT-2 model (12 attention\n",
    "> heads). Also ensure that you use the respective input and output embedding sizes\n",
    "> similar to GPT-2 (768 dimensions). Note that the smallest GPT-2 model supports a\n",
    "> context length of 1,024 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        return attn_output\n",
    "\n",
    "# GPT-2 smallest model configuration\n",
    "embed_dim = 768   # Hidden size\n",
    "num_heads = 12    # Number of attention heads\n",
    "context_length = 1024  # Maximum context length\n",
    "\n",
    "# Initialize the attention module\n",
    "attention = MultiHeadAttention(embed_dim, num_heads)\n",
    "\n",
    "# Create a sample input tensor (batch_size, context_length, embed_dim)\n",
    "x = torch.randn(1, context_length, embed_dim)\n",
    "\n",
    "# Forward pass\n",
    "output = attention(x)\n",
    "\n",
    "print(output.shape)  # Expected shape: (1, 1024, 768)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
